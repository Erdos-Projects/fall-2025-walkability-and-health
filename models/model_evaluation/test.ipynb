{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "768a98a6",
   "metadata": {},
   "source": [
    "# Cross-Validation & Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b975fc",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01875eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, cross_validate, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23918bc6",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab3c92d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['census_tract', 'StCoFIPS2019', 'StAbbr', 'walkability_index',\n",
       "       'Pop2018', 'HU2018', 'HH2018', 'employment_mix',\n",
       "       'employment_residential_mix', 'intersection_density',\n",
       "       'transit_accessibility', 'employment_mix_ranked',\n",
       "       'employment_residential_mix_ranked', 'intersection_density_ranked',\n",
       "       'transit_accessibility_ranked', 'median_income', 'percent_unemployed',\n",
       "       'percent_below_poverty', 'percent_bachelor_and_higher',\n",
       "       'percent_over_65', 'percent_commute_car', 'percent_commute_transit',\n",
       "       'percent_white', 'percent_black', 'percent_native_american',\n",
       "       'percent_asian', 'percent_pacific_islander', 'statedesc', 'countyname',\n",
       "       'total_population', 'arthritis_crudeprev', 'arthritis_crude95ci',\n",
       "       'high_blood_pressure_prevalence', 'high_blood_pressure_95ci',\n",
       "       'cancer_prevalence', 'cancer_95ci', 'current_asthma_prevalence',\n",
       "       'current_asthma_95ci', 'coronary_heart_disease_prevalence',\n",
       "       'coronary_heart_disease_95ci',\n",
       "       'chronic_obstructive_pulmonary_disease_prevalence',\n",
       "       'chronic_obstructive_pulmonary_disease_95ci', 'depression_prevalence',\n",
       "       'depression_95ci', 'diabetes_prevalence', 'diabetes_95ci',\n",
       "       'high_cholesterol_prevalence', 'high_cholesterol_95ci',\n",
       "       'kidney_disease_prevalence', 'kidney_disease_95ci',\n",
       "       'obesity_prevalence', 'obesity_95ci', 'phlth_crudeprev',\n",
       "       'phlth_crude95ci', 'stroke_prevalence', 'stroke_95ci', 'geolocation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the clean datasets\n",
    "\n",
    "df = pd.read_csv(\"data_train.csv\")\n",
    "df.sample()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbab324",
   "metadata": {},
   "source": [
    "## Model cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0a1583b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               target        model  rmse_mean   rmse_sd  \\\n",
      "26                  cancer_prevalence       Linear   1.721985  0.035342   \n",
      "28                  cancer_prevalence        Ridge   1.722342       NaN   \n",
      "29                  cancer_prevalence        Lasso   1.722347       NaN   \n",
      "27                  cancer_prevalence   PCA+Linear   1.722347       NaN   \n",
      "25                  cancer_prevalence  Dummy(mean)   1.867657  0.023959   \n",
      "21  coronary_heart_disease_prevalence       Linear   1.939565  0.043248   \n",
      "22  coronary_heart_disease_prevalence   PCA+Linear   1.940020       NaN   \n",
      "23  coronary_heart_disease_prevalence        Ridge   1.940044       NaN   \n",
      "24  coronary_heart_disease_prevalence        Lasso   1.940049       NaN   \n",
      "20  coronary_heart_disease_prevalence  Dummy(mean)   2.033882  0.031109   \n",
      "6               depression_prevalence       Linear   3.259604  0.111994   \n",
      "7               depression_prevalence   PCA+Linear   3.260497       NaN   \n",
      "8               depression_prevalence        Ridge   3.261510       NaN   \n",
      "9               depression_prevalence        Lasso   3.261529       NaN   \n",
      "5               depression_prevalence  Dummy(mean)   3.402604  0.116139   \n",
      "11     high_blood_pressure_prevalence       Linear   6.990228  0.210054   \n",
      "12     high_blood_pressure_prevalence   PCA+Linear   6.991838       NaN   \n",
      "13     high_blood_pressure_prevalence        Ridge   6.993362       NaN   \n",
      "14     high_blood_pressure_prevalence        Lasso   6.993384       NaN   \n",
      "10     high_blood_pressure_prevalence  Dummy(mean)   7.345990  0.220308   \n",
      "1         high_cholesterol_prevalence       Linear   4.274600  0.065923   \n",
      "3         high_cholesterol_prevalence        Ridge   4.275099       NaN   \n",
      "2         high_cholesterol_prevalence   PCA+Linear   4.275108       NaN   \n",
      "4         high_cholesterol_prevalence        Lasso   4.275109       NaN   \n",
      "0         high_cholesterol_prevalence  Dummy(mean)   4.718996  0.088089   \n",
      "16                 obesity_prevalence       Linear   6.270881  0.154057   \n",
      "18                 obesity_prevalence        Ridge   6.272766       NaN   \n",
      "17                 obesity_prevalence   PCA+Linear   6.272773       NaN   \n",
      "19                 obesity_prevalence        Lasso   6.272773       NaN   \n",
      "15                 obesity_prevalence  Dummy(mean)   6.684677  0.121124   \n",
      "\n",
      "                details  \n",
      "26                       \n",
      "28     best alpha=100.0  \n",
      "29     best alpha=0.001  \n",
      "27  best n_components=4  \n",
      "25                       \n",
      "21                       \n",
      "22  best n_components=3  \n",
      "23     best alpha=100.0  \n",
      "24     best alpha=0.001  \n",
      "20                       \n",
      "6                        \n",
      "7   best n_components=3  \n",
      "8      best alpha=100.0  \n",
      "9      best alpha=0.001  \n",
      "5                        \n",
      "11                       \n",
      "12  best n_components=3  \n",
      "13     best alpha=100.0  \n",
      "14     best alpha=0.001  \n",
      "10                       \n",
      "1                        \n",
      "3      best alpha=100.0  \n",
      "2   best n_components=4  \n",
      "4      best alpha=0.001  \n",
      "0                        \n",
      "16                       \n",
      "18     best alpha=100.0  \n",
      "17  best n_components=4  \n",
      "19     best alpha=0.001  \n",
      "15                       \n",
      "\n",
      "Saved results to results_cv_by_outcome.csv\n"
     ]
    }
   ],
   "source": [
    "# 1) Config\n",
    "features = [\n",
    "    \"employment_mix_ranked\",\n",
    "    \"employment_residential_mix_ranked\",\n",
    "    \"intersection_density_ranked\",\n",
    "    \"transit_accessibility_ranked\",\n",
    "]\n",
    "\n",
    "outcomes = [\n",
    "    \"high_cholesterol_prevalence\",\n",
    "    \"depression_prevalence\",\n",
    "    \"high_blood_pressure_prevalence\",\n",
    "    \"obesity_prevalence\",\n",
    "    \"coronary_heart_disease_prevalence\",\n",
    "    \"cancer_prevalence\",\n",
    "]\n",
    "\n",
    "group_col = \"StCoFIPS2019\"\n",
    "n_splits = 5\n",
    "\n",
    "# Preprocessing (numeric)\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"sc\", StandardScaler()),\n",
    "    ]), features)\n",
    "], remainder=\"drop\")\n",
    "\n",
    "# Base estimators / pipelines\n",
    "pipe_linear = Pipeline([(\"pre\", pre), (\"lr\", LinearRegression())])\n",
    "pipe_pca_linear = Pipeline([(\"pre\", pre), (\"pca\", PCA()), (\"lr\", LinearRegression())])\n",
    "pipe_ridge  = Pipeline([(\"pre\", pre), (\"ridge\", Ridge())])\n",
    "pipe_lasso  = Pipeline([(\"pre\", pre), (\"lasso\", Lasso(max_iter=10000))])\n",
    "\n",
    "# Small grids\n",
    "grid_pca   = {\"pca__n_components\": [2, 3, 4]}                # you have 4 features\n",
    "grid_ridge = {\"ridge__alpha\": [0.1, 1.0, 10.0, 100.0]}\n",
    "grid_lasso = {\"lasso__alpha\": [0.001, 0.01, 0.1, 1.0]}\n",
    "\n",
    "# CV splitter (grouped by county)\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "# Helper: convert neg MSE scores to RMSE mean & sd\n",
    "def mean_rmse_from_neg_mse(scores):\n",
    "    mses = -np.array(scores, dtype=float)\n",
    "    return float(np.sqrt(mses).mean()), float(np.sqrt(mses).std())\n",
    "\n",
    "rows = []\n",
    "\n",
    "for target in outcomes:\n",
    "    cols_needed = features + [target, group_col]\n",
    "    d = df.dropna(subset=cols_needed).copy()\n",
    "    if d.empty:\n",
    "        rows.append({\"target\": target, \"model\": \"N/A\", \"rmse_mean\": np.nan, \"rmse_sd\": np.nan, \"details\": \"No rows after dropna\"})\n",
    "        continue\n",
    "\n",
    "    X = d[features]\n",
    "    y = d[target]\n",
    "    groups = d[group_col]\n",
    "\n",
    "    # 0) Dummy baseline (predicts mean per train fold)\n",
    "    cv_dummy = cross_validate(\n",
    "        DummyRegressor(strategy=\"mean\"),\n",
    "        X, y,\n",
    "        cv=gkf.split(X, y, groups=groups),\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        n_jobs=-1, return_train_score=False\n",
    "    )\n",
    "    rmse_mean, rmse_sd = mean_rmse_from_neg_mse(cv_dummy[\"test_score\"])\n",
    "    rows.append({\"target\": target, \"model\": \"Dummy(mean)\", \"rmse_mean\": rmse_mean, \"rmse_sd\": rmse_sd, \"details\": \"\"})\n",
    "\n",
    "    # 1) Linear (no tuning)\n",
    "    cv_lin = cross_validate(\n",
    "        pipe_linear, X, y,\n",
    "        cv=gkf.split(X, y, groups=groups),\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        n_jobs=-1, return_train_score=False\n",
    "    )\n",
    "    rmse_mean, rmse_sd = mean_rmse_from_neg_mse(cv_lin[\"test_score\"])\n",
    "    rows.append({\"target\": target, \"model\": \"Linear\", \"rmse_mean\": rmse_mean, \"rmse_sd\": rmse_sd, \"details\": \"\"})\n",
    "\n",
    "    # 2) PCA -> Linear (tune n_components)\n",
    "    gs_pca = GridSearchCV(\n",
    "        pipe_pca_linear, grid_pca,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        cv=gkf.split(X, y, groups=groups),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    gs_pca.fit(X, y)\n",
    "    rows.append({\n",
    "        \"target\": target, \"model\": \"PCA+Linear\",\n",
    "        \"rmse_mean\": float(np.sqrt(-gs_pca.best_score_)), \"rmse_sd\": np.nan,\n",
    "        \"details\": f\"best n_components={gs_pca.best_params_.get('pca__n_components')}\"\n",
    "    })\n",
    "\n",
    "    # 3) Ridge (tune alpha)\n",
    "    gs_ridge = GridSearchCV(\n",
    "        pipe_ridge, grid_ridge,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        cv=gkf.split(X, y, groups=groups),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    gs_ridge.fit(X, y)\n",
    "    rows.append({\n",
    "        \"target\": target, \"model\": \"Ridge\",\n",
    "        \"rmse_mean\": float(np.sqrt(-gs_ridge.best_score_)), \"rmse_sd\": np.nan,\n",
    "        \"details\": f\"best alpha={gs_ridge.best_params_.get('ridge__alpha')}\"\n",
    "    })\n",
    "\n",
    "    # 4) Lasso (tune alpha)\n",
    "    gs_lasso = GridSearchCV(\n",
    "        pipe_lasso, grid_lasso,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        cv=gkf.split(X, y, groups=groups),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    gs_lasso.fit(X, y)\n",
    "    rows.append({\n",
    "        \"target\": target, \"model\": \"Lasso\",\n",
    "        \"rmse_mean\": float(np.sqrt(-gs_lasso.best_score_)), \"rmse_sd\": np.nan,\n",
    "        \"details\": f\"best alpha={gs_lasso.best_params_.get('lasso__alpha')}\"\n",
    "    })\n",
    "\n",
    "# Summarize & save\n",
    "results = pd.DataFrame(rows).sort_values([\"target\", \"rmse_mean\"])\n",
    "print(results)\n",
    "results.to_csv(\"results_cv_by_outcome.csv\", index=False)\n",
    "print(\"\\nSaved results to results_cv_by_outcome.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f14fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_ds_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
